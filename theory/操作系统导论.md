# 操作系统导论

[TOC]

![image-20221208072939481](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212080729525.png)

![image-20221225110541274](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212251105378.png)

![image-20230111085050783](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301110850871.png)



## 操作系统介绍

**虚拟化**：将硬件资源（CPU 内存 磁盘） 转化为更通用 更易用的虚拟形式

- 虚拟化CPU：

  虽然只有一个物理核 但是可以并发运行多个进程 看上去就像是有多个物理核

- 虚拟化内存：

  每个进程访问的都是自己独立的虚拟地址空间 即使两个进程中打印的内存地址一样 物理内存中也是处于不同的地方 操作系统会将虚拟地址映射为物理地址

**并发**

并发会带来线程安全问题，所以需要操作系统提供原语 硬件提供机制

**持久性**

内存的数据是断点消失的 所以数据需要持久化到磁盘



**操作系统的设计目标**

- 建立抽象 屏蔽底层系统细节 提供易用的接口给上层系统
- 最小化操作系统的开销
- 隔离OS与应用进程 隔离不同的应用进程
- 可靠性 需要不间断运行
- 安全性



**发展历史**

1. 批处理 先将需要运行的程序准备好 然后让操作员手动分批执行
2. 提供了系统调用 区分了用户态和内核态
3. 多道程序 进程切换





## 抽象：进程

进程：操作系统为正在运行的程序提供的抽象 



**进程是如何创建的**

1. 操作系统需要将代码和静态数据加载到内存进程的地址空间中（现在都是延迟加载 真正需要执行时才加载） 
2. 为进程分配堆和栈
3. 执行IO设置相关的工作 标准输入 输出 错误



**进程状态**

- 运行：分配到了CPU时间片 正在执行指令
- 就绪：已准备好运行 但是未分配到CPU时间片
- 阻塞：等待阻塞事件完成



**数据结构**

PCB(或者process list)

PCB中包含有进程运行时的寄存器数值信息（也即上下文）

![image-20221216070450613](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212160704692.png)

![image-20221216070540129](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212160705157.png)

进程僵尸状态：已退出但是尚未清理





## 插叙：进程API

- fork创建子进程
- wait等待子进程完成
- exec将当前进程替换为不同的运行程序

分离fork和exec原因：给了shell在fork之后 exec之前运行代码的机会 可以在运行新程序前改变环境





## 机制：受限直接执行

> 虚拟化CPU的基本机制

虚拟化CPU的问题：

- 性能：

  不增加系统开销的情况下实现虚拟化

- 控制权：

  不能让进程无限制地接管机器 访问没有权限的信息



**基本技巧：受限直接执行**

![image-20221218071618238](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212180716292.png)

问题：

- 操作系统怎么确保程序不做任何我们不希望它做的事 同时高效运行程序
- 运行进程时 操作系统如何让它停下来并切换到另一个进程



**受限制的操作**

划分处理器模式：

- 用户模式：运行应用程序 这个模式下进程不能发起IO请求
- 内核模式：内核运行的模式 运行的代码可以执行所有特权操作

如何让进程能够执行IO和其他受限制的曹组 但又不能让进程完全控制系统？

系统调用：内核向用户程序暴露的接口

陷阱表：trap指令 -> 对应的处理程序位置

![image-20221218075431019](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212180754051.png)





**在进程之间切换**

问题：操作系统如何重新获取CPU的控制权

方法：

- 协作方式：等待系统调用或非法操作发生 
- 非协作方式：时钟中断 中断发生时 当前运行的进程停止 转而执行操作系统设置的中断处理程序（由硬件保存和恢复上下文）



**保存和恢复上下文**

操作系统将当前进程运行时的寄存器值（通用寄存器 PC 内核栈指针）保存到内核栈中

将将要执行的进程的寄存器值从它的内核栈中恢复

> 内核在创建进程的时候，在创建task_struct的同时，会为进程创建相应的堆栈。每个进程会有两个栈，一个用户栈，存在于用户空间，一个内核栈，存在于内核空间。当进程在用户空间运行时，cpu堆栈指针寄存器里面的内容是用户堆栈地址，使用用户栈；当进程在内核空间时，cpu堆栈指针寄存器里面的内容是内核栈空间地址，使用内核栈。
> 当进程因为中断或者系统调用而陷入内核态之行时，进程所使用的堆栈也要从用户栈转到内核栈。
>
> 进程陷入内核态后，先把用户态堆栈的地址保存在内核栈之中，然后设置堆栈指针寄存器的内容为内核栈的地址，这样就完成了用户栈向内核栈的转换；当进程从内核态恢复到用户态之行时，在内核态之行的最后将保存在内核栈里面的用户栈的地址恢复到堆栈指针寄存器即可。这样就实现了内核栈和用户栈的互转。
>
> 那么，我们知道从内核转到用户态时用户栈的地址是在陷入内核的时候保存在内核栈里面的，但是在陷入内核的时候，我们是如何知道内核栈的地址的呢？
>
> 关键在进程从用户态转到内核态的时候，进程的内核栈总是空的。这是因为，当进程在用户态运行时，使用的是用户栈，当进程陷入到内核态时，内核栈保存进程在内核态运行的相关信息，但是一旦进程返回到用户态后，内核栈中保存的信息无效，会全部恢复，因此每次进程从用户态陷入内核的时候得到的内核栈都是空的。所以在进程陷入内核的时候，直接把内核栈的栈顶地址给堆栈指针寄存器就可以了。

![image-20221219075227476](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212190752518.png)

> switch()例程：通过改变栈指针来使用新的进程的内核栈



```java
2022-12-23 17:51:26.377 ERROR 1 --- [ool-28-thread-1] c.m.c.d.service.RouteService             : route error route:developer/openTsLog2S content:{ "dsId": "P_ad533f9c190983b414d5d60ea5687cf6269e4b00-19ca505382b4479cb8aeeb8a5099684b", "open": "true"} error:No provider available from registry metaapp-nacos.default:8848 for service developer/com.metaverse.cobblestone.developergate.api.inter.DeveloperClientReceiverDubboServiceApi:1.0.0 on consumer 10.27.16.169 use dubbo version 2.7.8, please check status of providers(disabled, not registered or in blacklist).
```



## 进程调度：介绍

**工作负载假设**

- 工作运行时间相同
- 所有工作同时到达
- 一旦开始 每个工作保持运行直至完成（非抢占）
- 所有工作只使用CPU 不执行IO操作
- 工作的运行时间已知



**调度指标**

- 周转时间 = 任务完成时间 - 任务到达时间
- 响应时间 = 首次运行时间 - 任务到达时间（与终端相关的交互性任务）



**调度算法**

需要最小化平均周转时间

- 先来先服务（FCFS）

- 最短任务优先（SJF）

- 最短完成时间优先（STCF）（抢占式） 有利于周转时间 但是对响应时间不利

  每当新工作进入系统就会确定剩余工作和新工作中 谁的剩余时间最少

- 轮转：有利于响应时间 但是对周转时间不利

  时间片太短时 上下文切换的时间在整体运行时间的占比就会增加 

  摊销的思想：减少成本的频度 降低系统的总成本



## 调度：多级反馈队列

目的：在事先不了解工作长度的情况下

- 优化周转时间

  通过运行短工作 但问题是操作系统并不提前知道工作的运行时间

- 降低响应时间

  轮转调度的周转时间很长



**多级反馈队列**： *multi-level feedback queue*

设计：使用历史经验预测未来

MLFQ中有许多独立的队列 每个队列的优先级不同 总是执行优先级较高的工作  同一个队列中的任务采用轮转调度

规则:

- A优先级 > B 运行A

- A B优先级相同 轮转运行 A B

- 工作进入系统时 放在最高优先级

- 工作用完整个时间片后 降低其优先级（计算密集型）

- 如果工作在时间片内主动释放CPU 优先级不变（IO密集型）

  改进：一旦工作用完了其在某一层的时间配额（不管是否主动放弃CPU）都降低其优先级 移入下一层队列 避免进程恶意放弃CPU保持优先级

- 经过一段时间 将系统所有工作重新加入最高优先队列（避免饥饿 保证长工作能定期得到执行）

关键：动态调整优先级







## 调度：比例份额

目标：确保每个工作获得既定比例的CPU时间

彩票调度基本概念：

每个进程拥有的彩票数 代表其占有某个资源的份额  每个时间片结束时 抽取彩票 拥有这个数的彩票进程中奖

> 利用随机性的优势：
>
> - 避免最差情况
> - 轻量 不需要记录太多状态
> - 快

彩票机制：

- 彩票货币：用户可以自定义自己内部的数额 但是跟全局兑换时 需要按照啊一定的比例
- 彩票转让：进程可以临时将自己的彩票交给另一个进程 比如同一个机子上的C/S交互 客户端可以临时将自己的彩票份额交给服务端 加快任务的执行 任务执行完后 彩票归还客户端
- 彩票通胀：进程可以临时提升或降低自己的彩票数量 一般用于进程相互信任的环境

实现：

随机数生成器 + 链表（节点中的信息为进程 + 进程拥有的彩票数）



**步长调度**

解决的问题：彩票调度的随机方式 在运行时间很短的情况下 不能产生正确的比例

设计：工作的步长与票数成反比 每次进程运行后 其行程值会累加 每次调度时 都选择当前行程值最小的进程

问题：需要全局状态 新加入的进程的行程值不好设置 



彩票调度和步长调度的共同问题：怎么给不同的进程分配票数（在虚拟化环境下分配不同容器CPU资源时可以使用）



## 多处理器调度

**多CPU与单CPU的基本区别**：

- 对硬件缓存的使用：需要考虑缓存一致性的问题 

  硬件的解决方案是使用总线窥探 CPU缓存监听链接缓存和内存的总线 如果发现有对缓存中数据的更新 就将本地副本作废或者更新（MESA）

- 共享数据的方式

  并发修改数据需要同步

- 缓存亲和度（cache affinity）

  进程在一个CPU上运行时 会在CPU的缓存中维护许多状态（L1 L2缓存） 下次再相同的CPU运行时会执行得更快（局部性原理） 如果更换CPU则需要重新从内存加载数据



**多CPU下任务的调度方式**

- 单队列多处理器调度

  优点：无需修改单CPU下的策略

  缺点：

  - 扩展性和性能差：多个CPU从单个队列中取任务时 需要加锁保证原子性 加锁带来了性能瓶颈
  - 缓存亲和性：很难保证一个任务大概率在同一个CPU上运行

  ![image-20221227072731529](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212270727633.png)

- 多队列多处理器调度

  一个CPU对应一个调度队列 不同的队列可以使用不同的调度规则

  优点：避免了单队列情况下的加锁 提升了扩展性与性能 也照顾到了缓存亲和性

  问题：CPU负载不均衡 有的CPU空闲 有的CPU忙

  解决：工作窃取 工作量少的队列不定期偷看其他队列是不是比自己工作多 是则从目标队列窃取工作 实现负载均衡

​		



## 抽象：地址空间

**早期系统**

内存 = 操作系统 + 一个正在运行的程序



**多道程序和时分共享**

多个进程在给定时间内执行 当一个进程等待IO时 释放CPU切换另一个进程 多个进程的状态信息都保存在内存中 这也带来了保护的需求（隔离不同进程的物理内存）

![image-20221228043619416](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212280436470.png)

**地址空间**

对物理内存的抽象，是进程看到的系统中的内存

组成：代码 + 堆 + 栈



**内存虚拟化**：

概念：让进程认为自己拥有一个从地址0开始的很大的地址空间

目标：

- 透明：进程感知不到内存虚拟化
- 效率：时间（程序不会运行得更慢） 空间（不会占用过多的额外内存）
- 保护：确保进程（包括内核）不会受到其他进程影响 自身地址空间的内容不会被其他进程访问



## 插叙：内存操作API

**malloc和free的常见错误**

- 忘记分配内存给目的指针 导致段错误（读写不允许的内存空间）
- 没有分配足够的内存（缓冲区溢出）
- 没有初始化分配的内存
- 忘记释放内存
- free之后 再次使用该内存
- 反复释放内存



**进程退出时 没有内存泄漏的原因**

两级内存管理：

- 第一级：

  操作系统执行的 

  进程运行时 分配内存给进程

  进程结束时 将分配的内存回收

- 第二级：

  进程的堆中 通过malloc和free管理

  > 支撑malloc的系统调用：brk 改变堆结束的位置



## 机制：地址转换

地址转换：

- 硬件：将指令中的虚拟地址转换为物理地址
- 操作系统：设置硬件 管理内存



假设：

- 用户的地址空间是连续放在物理内存中的
- 用户地址空间小于物理内存
- 用户地址空间大小完全一样



**动态重定位**

> 早期的静态重定位：
>
> 加载程序将将要运行的可执行程序中的地址改写为物理内存中期望的地址
>
> 问题：
>
> - 不提供访问保护 可能访问到其他进程或操作系统的内存
> - 不能在运行中进行内存空间的重定位

初期：基址 + 界限（由CPU中的基址寄存器和界限寄存器负责 MMU 内存管理单元）

地址转换：虚拟地址 + 基址寄存器中的地址 = 物理地址 如果转换后的物理地址超过了这个界限 CPU将触发异常 进程可能被终止





**硬件对动态重定位的支持**

- 特权模式
- 基址 界限寄存器（每个CPU一对）
- 转换虚拟地址并检查是否越界（电路完成）
- 修改基础 界限寄存器的特权指令（操作系统设置）
- 注册异常处理程序的特权指令（操作系统设置）
- 能够触发异常（当进程越权访问时）



**操作系统对动态重定位的支持**

- 内存管理：为新进程分配内存 为终止的进程回收内存 通过空闲列表来管理内存
- 基址 界限管理：在上下文切换时 设置正确的基址 界限寄存器
- 异常处理：设置异常发送时执行的代码 一般的动作是终止该进程



基址+界限的问题：会带来内存碎片



## 分段

最初的动态重定向带来的问题：

需要将进程的整个地址空间都加载到内存中 堆和栈之间存在很大一部分未利用空间



**分段**

原来是给每个进程分配一对基址和界限寄存器 现在是给进程中的每个逻辑段分配一对，不同的段可以放入物理内存的不同区域 避免了虚拟地址空间中的未使用部分占用实际的物理内存



**硬件地址转换时 怎么知道该虚拟地址属于哪个段和段内偏移**

- 显式：

  虚拟地址 = 高位的段标识 + 低位的段内偏移

- 隐式：通过地址产生的方式

  代码段：程序计数器产生（可以代码共享）

  栈段：基于栈

  堆段：其他

![image-20230109073438278](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301090734331.png)

> 注意：栈的物理空间是向低地址反向增长的



**为支持分段 操作系统需要做的事**

- 在上下文切换的时候 需要做什么

  保存与恢复各个段寄存器

- 管理物理内存的空闲空间

  问题：分配内存大小不一的段会造成外部内存碎片

  解决方法：

  - 紧凑物理内存（有点像垃圾回收算法）
  - 用空闲列表管理算法 从空闲链表中找出最合适的块返回
  - 不要分配不同大小的内存块



分段存在的问题：

- 产生外部碎片
- 当一个很大但是很稀疏的堆在一个逻辑段内时 还是会有很多物理空间被浪费



## 空闲空间管理

需要处理的问题：

当管理的空闲空间大小不一时 需要满足变长的分配请求 应该如何管理空闲空间 才可以让外部碎片最小化



假设：

- 主要关心外部碎片的问题
- 内存一旦分配给用户 就不可用被重定位到其他位置（不能进行通过移动 紧凑空闲空间的操作）
- 分配程序管理的字节区域是连续且固定的



**底层机制**

- 分割与合并
  - 分割：当申请的空间 < 该空闲内存块的空间时 会将其分割 剩余部分留在空闲列表中
  - 合并：当一块空闲内存被归还时 如果与其他空闲块相邻 就将其合并为一个较大的空闲块
  
- 追踪已经分配空间的大小

  （因为释放空间的时候 只传了首地址 所以分配程序需要知道已经出去的空间块的大小）

  通过给每个被分配的空间块加上元信息即可 元信息中包含了该块的大小（所以实际malloc和free的空间大小是申请的size+元信息数据结构大小）

  ![image-20230112120145303](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301121201357.png)

- 嵌入空闲列表

  空闲列表有一个头指针 指向第一个空闲块 空闲块也是元信息+空闲块空间  元信息里面有大小和下一个空闲块的地址 （元信息是为了让信息可以自解释）

  ![image-20230112123054275](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301121230304.png)

- 让堆增长

  执行sbrk系统调用 操作系统会找到空心啊的物理内存页 然后映射到请求进程的地址空间中（修改页表） 并返回堆的末尾地址



**基本策略**

- 最优匹配：遍历整个列表 找到最接近申请大小的块
- 最差匹配：遍历整个猎豹 找到最大的空闲块 会造成过多的碎片
- 首次匹配：找到第一个合适的就分配 速度快 并且空闲列表可以根据地址排序 便于回收时 合并操作
- 下次匹配：首次匹配迭代版 每次都从上次查找结束的位置开始 进行首次匹配



内存分配的其他策略：

- 分离空闲列表：

  用一部分内存专门满足某种固定大小的请求 这样就不会有内存碎片了

- 二分伙伴系统：

  为了方便合并 分配是 向下二分拆分 直到无法再分 空间返还时 递归向上合并（互为伙伴的块地址 只有一bit不同）

  ![image-20230112210746995](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301122107032.png)



## 分页

> 将空间分割成固定长度的分片

**页表**：

用于虚拟页号 -> 物理帧号的转换

每个进程一个

虚拟地址组成：虚拟页号 + 偏移量

![image-20230113120518843](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301131205895.png)



页表项的内容：

- 物理页帧

- 有效位：无效的虚拟页不需要为其分配物理帧
- 保护位：页是否可以读取 写入 执行
- 存在位：在内存中 还是被缓存到磁盘上了
- 脏位：页被带入内存后是否被修改过（影响到后面写盘）
- 访问位：追踪页的访问情况 （页面替换时用到）



分页存在的问题：

- 空间消耗：

  32位地址空间 20bit给虚拟页号 12bit给偏移量

  不做任何优化的情况下 操作系统需要为一个进程分配 2^20个页表项 假设页表项大小为4B

  则页表大小为4MB

- 时间消耗：

  ```assembly
  movl 21, %eax
  ```

  转换步骤:

  1. 根据当前进程自己的页表基址寄存器 拿到页表基址(这样就多了一次跟内存的交互)
  2. 页表基址 + 虚拟地址中的虚拟页号拿到物理帧号
  3. 物理帧号 + 虚拟地址中的偏移量 拼接成物理地址



## 分页：快速地址转换 TLB

解决的问题：分页带来的额外的时间消耗

分页后 将虚拟地址转换为物理地址时  需要一次额外的内存访问 获取页表项

解决方法：加缓存

VPN -> FPN 查询时 先查TLB TLB查到则直接返回

查不到则去内存中找出页表项 并将页表项的内容插入TLB 再次进行一次查找 这样下次就会命中TLB



场景：访问数组

假设访问数据第一个元素时 该元素所在页在TLB中找不到映射 则去内存中补充回来 后面一页(4KB)的元素的TLB都会是命中的（空间局部性）



**谁负责处理TLB未命中的情况**

- 硬件：对应复杂指令集

  硬件可以通过页表基址寄存器获取页表基址 并需要知道页表的格式 TLB未命中时可以遍历页表找到页表项 更新TLB

- 操作系统：对应精简指令集

  当发生TLB未命中时 硬件会抛出一个异常 跳转到陷阱处理程序 操作系统需要设置好这个陷阱处理程序的逻辑：查找页表 更新TLB

  细节：

  - 从陷阱处理程序返回时 需要回到同一条执行指令 而不是下一条（继续走TLB）
  - 写TLB未命中代码时 操作系统需要避免代码自身也有TLB未命中的情况 导致无限递归

  优势：

  - 灵活： 操作系统可以用任意数据结构来实现页表，无需改变硬件
  - 简单：硬件不需要做太多工作 只需要抛出异常



**TLB的内容**

- VPN
- FPN
- 其他位：
  - 全局位：用来指示这个页是不是所有进程全局共享的
  - ASID：区分进程空间
  - 脏位
  - 有效位：该映射是否有效
  - 页掩码：支持不同的页大小（一般用于DBMS这种 避免频繁的TLB miss）



**上下文切换时对TLB的处理**

问题：TLB中包含的虚拟->物理的映射 只对当前进程有效 进程切换后 需要保证转换正确

解决：

- 有效位 置0：

  切换时 将TLB所有映射设为无效，当时这样会频繁触发TLB未命中

- 在TLB中的其他位中加上ASID地址空间标识符（区别进程）：

  上下文切换时 将某个寄存器设置为当前进程的ASID

  这样还有一个好处是当多个进程共享同一个物理页时  两个映射都可以在TLB中被找到

  ![image-20230116083602081](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301160836141.png)





## 分页：较小的表

解决的问题：分页带来的额外的空间消耗

分配给每个进程的页表太大 消耗的内存太多 

解决的方法：

- 增大页的大小：可以在同样空间下 减少页表项

  然而会导致内部碎片

- 分页+分段：

  页表大部分页表项都是无效的 都没有使用

  代码 堆 栈各一个线性页表 一个段有几页 页表中就只分配几个页表项 这样栈和堆之间未分配的空间就不会再占用页表的空间

  缺点：

  - 一个大而稀疏的堆 还是会导致页表项浪费
  - 页表是任意大小的 为页表项申请内存空间时还是会导致外部碎片

- 多级页表

  基本思想：

  将页表项以页为单元组织起来 如果整个页内没有一个页表项是有效的 那就完全不分配该页的页表 

  引入二级索引 页目录 可以告诉页表项所在的页在哪里 页表的整个页是否包含有效页

  时间换空间：减少了页表的实际占用内存 但是如果TLB miss需要额外两次查询内存

  

**反向页表**

整个内存中只有一个页表：物理页到进程的映射





## 超越物理内存：机制

问题：多道程序和易用性都需要操作系统支持比物理内存更大的虚拟地址空间



**交换空间**

在硬盘上开辟的一部分用于物理页的移入移出的空间，操作系统需要记住被交换到硬盘上的页的硬盘地址 



**存在位**

页表项中的一个标识位，标识进程的该页是否在物理内存中，如果地址转换的时候 发现页不在内存中 这种现象就是页错误



**页错误**

当发生页错误时 由操作系统设置的页错误处理程序来确定需要做什么

页错误时 操作系统会先从页表项中找到硬盘地址 向硬盘发起IO请求 将页读到内存中 然后修改页表项 将存在未置为true，同时更新页表项中的PFN字段，重试指令

下次访问TLB miss
再下次访问TLB 命中



**交换发生的时机**

为了保证换入页时有足够多可用的物理帧 操作系统将可用的物理页维持在一个范围内（低水位-高水位），少于低水位个页的情况下 操作系统会启动一个后台进程（交换守护进程）进行释放内存

优化点：同时执行多个交换过程时，可用将要写入的页聚集起来 ，再一次性写入 这样可以减少硬盘的寻道和旋转开销



