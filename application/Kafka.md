# Kafka

[TOC]

## 入门

### 消息引擎系统ABC



**定义**

> 一款开源的消息引擎系统 Messaging System



消息引擎系统：

> **定义**：
>
> 维基百科：是一组规范，企业利用这组规范在不同系统间传递语义准确的消息，实现松耦合的异步式数据传递
>
> 民间：系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送的消息
>
> 两个关键点：
>
> - 消息引擎传输的对象是**消息**
> - **如何传输消息**属于消息引擎设计的一部分
>
> 需要解决的问题：
>
> - 消息编码格式的设计
>
>   kafka: 结构化的二进制的字节序列
>
> - 设定具体的传输协议：用什么办法把消息传输出去
>
>   点对点：一个消息由一个生产者发出，只能给一个消费者消费
>
>   发布/订阅：有topic的概念，topic是逻辑语义相近的消息容器
>
>   一个topic的生产者和消费者都可以有多个



为什么需要消息引擎系统，而不是直接向对方系统发送信息：

- **削峰填谷**
- 解耦发送方与接收方



两个进程之间进行数据交互的方式：

- 通过数据库/磁盘文件：进程A写库，进程B读库
- 通过服务调用：REST RPC
- 通过消息传递：经由消息引擎系统





### Kafka术语



**主题**：*topic*. 是生产者发布和消费者订阅的对象

**生产者**：向主题发布消息的客户端应用程序，可以向一个或者多个主题发布消息

**消费者**：订阅主题消息的客户端应用程序，可以同时订阅多个主题的消息

**客户端**：生产者和消费者

**服务器端**：由被称为Broker的服务进程构造，一个Kafka集群由多个Broker构成，通常部署在不同机器上，

> Broker的作用：
>
> - 接收和处理客户端发送的请求
> - 对消息进行持久化



**实现高可用的手段**：

- 实例集群，将Broker部署在不同的机器上，一台挂掉了，也可以由其他的Broker提供对外服务
- 备份机制 *replication*：将相同的数据拷贝（副本 *Replica*）到多台机器上



**副本**：

类型：

- 领导者副本：跟客户端交互
- 跟随者副本：跟随领导者副本，不与客户端交互

工作机制：

生产者向领导者副本写消息，消费者从领导者副本读消息

追随者副本：向领导者副本发送请求，将领导者最新生产的消息发给它，保持数据同步



**分区 *partitioning***：将数据分割成多份保存在不同的Broker中（通过不同分区的领导者副本分布在多个Broker中）

将每个主题划分成多个分区，每个分区都是一个组有序的消息日志，生产者发布的每条消息只会发送到该主题的一个分区中



**分区与副本的关系**

副本是分区这个层级下的概念，一个分区下可以有多个副本（一个副本在一个broker中），由一个领导者副本和多个跟随者副本构成



**分区位移**

每条消息在分区中的位置信息



**消息架构**

- 主题层：一个主题可以配置M个分区，一个分区可以配置N个副本（根据Broker数量）
- 分区层：每个分区的N个副本中只能有一个充当领导者角色，与客户端交互，其他副本提供数据冗余
- 消息层：一个分区中包含多条消息，消息的位移从0开始递增



**Broker持久化数据的方式**

使用消息日志 *Log*，来保存消息数据，一个日志就是物理磁盘上一个只能追加写的文件，采用的IO操作为性能较好的顺序IO写操作

日志中由多个日志段组成，后台会有定时任务定期地检查老的日志段是否能够被删除



**消费者组**：实现了P2P的消息模型

由多个消费者实例组成，来共同消费一组主题，主题中不同分区的领导者副本被不同的消费者消费



**重平衡 *Rebalance***

当消费者组中某个实例挂掉了，Kafka会检测到，并将这个实例之前负责的分区转移给其他活着的消费者



**消费者位移**：消费者在消息消费的过程中需要有一个字段记录消费到了分区的哪个位置（消费进度的指示器）



![](https://static001.geekbang.org/resource/image/58/91/58c35d3ab0921bf0476e3ba14069d291.jpg)

问题：为什么Kafka中的追随者副本不像Mysql一样对外提供服务（从读）

- 数据从Leader副本同步到Follower副本需要时间
- 从读是为了减轻主节点的压力，但是如果各个分区的Leader副本均匀分散在不同的Broker上，也可以达到负载均衡的效果



> Kafka是消息引擎系统，也是分布式流处理平台
>
> 设计之初的三个目的
>
> - 提供一套API实现生产者和消费者
> - 降低网络传输和磁盘存储开销
> - 实现高伸缩架构





### kafka版本号

版本号组成：大 + 小 + patch

**版本更迭**

- 0.7：只提供了最基础的消息队列功能 无副本

- 0.8 ：引入了副本机制 成为一个完备的分布式高可靠消息队列解决方案

  建议使用0.8.2.2版本 不建议使用0.8.2.0之后的producer API

- 0.9： 增加了基础的安全认证/权限功能 用Java重写了消费者API 引入了Kafka Connect组件

  不建议使用consumer API

- 0.10：引入了Kafka Streams 正式升级成为分布式流处理平台

  建议版本0.10.2.2 建议使用新版consumer API

- 0.11 producer API幂等 事务API 消息格式重构 建议版本0.11.0.3 

- 1.0 2.0：Kafka Streams的改进 建议版本2.0

**经验**

- 注意消息格式的变化
- 客户端的版本保持与服务端的一致（为了优化）
- 不要成为最新版本的小白鼠





## 基本使用



### Kafka线上集群部署方案



**部署需要考虑的因素**

- 操作系统
- 磁盘
- 带宽



**操作系统**

Linux的优势：

- IO模型的使用

- 数据网络传输效率

  Zero Copy 避免数据拷贝

- Kafka社区支持度



IO模型：越后面的性能越好

- 阻塞式IO：Java Socket对象阻塞模式
- 非阻塞式IO：Java Socket对象非阻塞模式
- IO多路复用：Linux select
- 信号驱动IO: epoll
- 异步IO

Kafka客户端：Java selector 在Linux上的实现是epoll 在Windows上的实现是select



**磁盘**

追求性价比，使用机械磁盘即可



**磁盘容量**

需要考虑的因素：

- 新增消息数
- 消息留存时间
- 平均消息大小
- 备份数
- 是否启用压缩 压缩比



**带宽**

千兆网： 1Gbps

假设单台服务Kafka使用的带宽是240Mb 最多使用70%的带宽

如果一个小时要处理1TB=8Tb=8000Gb=8000000Mb的数据

那每秒需要处理2222Mb的数据

所以需要10台服务器（服务器上只跑Kafka 其他的不跑）

如果消息还需要额外复制一份 -> 20台





### 集群参数配置



**Broker端参数配置**

- 存储消息相关：不同的目录最好挂载不同的磁盘中 提高IO效率 实现故障转移
- Zookeeper相关：zookeeper中存储了kafka的所有元信息：broker topic 分区 Leader副本
- broker连接相关：用什么协议与Broker进行通信
- Topic相关 ：是否允许自动创建Topic Leader选举相关
- 消息的留存：留存时间 留存空间 单个消息最大容量 



**Topic相关配置**

- 消息的留存时间和空间
- 消息的尺寸



**JVM相关配置**

- 堆大小
- GC



**操作系统相关配置**

- 文件描述符数量
- 文件系统
- swap
- 页缓存



## 客户端实践及原理剖析



### 生产者消费分区机制

**Kafka消息层级**

1. 主题：某类消息

2. 分区：读写单位 一个主题中的消息分布在多个分区中 消息在分区之间互不重叠

   ​			每个分区又可以配置多个副本 副本之间数据是需要同步的

   ​		    其中领导者副本负责实际的与外部的交互 

3. 消息：存储单位



**分区的作用**

- 负载均衡 多分区之后 让每个分区的领导者副本在不同的Broker中 
- 高伸缩性：可通过增加分区 增加节点的方式水平扩容 提高处理能力



**分区策略**：决定某个消息会被放到哪个分区中

- 默认策略：如果有Key 就对Key作哈希 然后取余

  ​					没有Key就是轮询

- 轮询策略：分布最均匀

- 随机策略

- 按Key做Hash：可保证同一个Key的消息放到同一个分区中 被顺序消费

- 自定义策略



### 生产者压缩算法

**压缩作用**：时间换空间 更高的CPU使用 换取更少的存储空间和网络带宽占用



**消息格式**

消息集合：消息项组成

压缩的对象是整个消息集合



**压缩**：

- 生产者端进行压缩

- broker端也会进行压缩：

  - 指定了broker端的压缩算法时 broker会先解压（如果producer压缩了）再压缩

  - 当消息格式不一致时（存储用的还是老的消息格式）broker先解压 转换消息格式 再压缩

    **会丧失Zero Copy的特性**



**解压**

- Broker解压
- Consumer解压



一般是producer压缩 broker存储 不做动作 consumer解压



**压缩算法**

算法需要考虑的因素：

- 压缩比：zstd最高
- 压缩速率: lz4最快



**最佳实践**

如果CPU资源不紧张 推荐使用zstd压缩算法 节省带宽资源和存储空间



### 无消息丢失配置

**Kafka的保证**

> 对已提交的消息 作有限度的持久化保证



**生产者导致的丢消息场景**

- 消息没能到达Broker （网络抖动）
- 消息大小/格式不符合Broker要求 导致Broker拒绝接收该消息



**消费者导致的丢消息的场景**

需要保证的顺序：

1. 先消费消息
2. 再提交消费位移



- 先提交位移 再消费数据 但是并没有消费完
- 单个Consumer多个线程消费 有的线程没有消费完 就提交位移了



**配置**

- Producer端

  发送时设置回调函数 处理发送失败的情况

  设置重传次数

  将已提交定义为所有的broker都接收到了之后

- Broker端

  

- Consumer端

  先消费 再提交





### 客户端中的拦截器功能



**生产端拦截器**

- 消息发送前
- 消息提交后



**消费端拦截器**

- 消费消息前
- 消费位移提交后



**应用场景**

计算消息的端到端的平均延时





### Java生产者管理TCP连接



**选用TCP协议的原因**

- 可以利用TCP多路复用特性
- TCP客户端支持的语言多



**TCP连接的建立**

- 生产者实例创建时 会开启一个sender线程 与配置中的所有的Broker建立TCP连接
- 当从Broker中获取的元数据时 会建立与所有的broker的连接
- 当发送消息 发现没有与该broker建立连接时 会建立与该Broker的连接



**TCP连接的断开**

- 生产者close 或者生产者进程挂掉
- broker断开  客户端感知不到（超过空闲时间）





### 幂等生产者与事务生产者



**消息精准交付的语义**

- 最多一次

  消息可能丢失 但不会重复

- 至少一次

  消息不会丢失 但可能重复

- 精确一次

  消息不会丢失 不会重复



**幂等生产者**

幂等性：一个函数执行一次和执行多次的结果是一样的 不会改变系统状态

幂等生产者局限性：

- 仅限于单分区
- 仅限于但会话：Producer进程重启就没了



**事务生产者**

能保证多分区 多会话之间的事务性 多个消息要么全部提交 要么全部不提交

但是会影响性能





## 初识Kafka

**概念**：

- offset：消息在分区中的唯一标识 在被添加到分区日志文件时分配

- 一个主题可以有多个分区 存储一个主题中不同的消息 利用多个机器的性能

  一个分区存储层面可以看作一个可追加的日志文件

- 副本集合：

  副本是用于实现高可用

  集合：

  AR（某个分区的所有副本） = ISR(In-Sync) + OSR(Out-of-Sync)
  
  In-Sync的含义：并非follower和leader完全一致 而是在可忍受的范围内滞后
  
  分区的HW：high watermark 高水位 标识了一个offset 消费者只能拉取到这个offset之前的消息（可靠性） ISR中min(LEO)
  
  LEO：当前日志文件下一条待写入消息的offset



消息队列的复制机制：

- 同步复制：

  当所有follower副本都复制完 消息才被认为是成功提交(ack=all)

- 异步复制：

  只要leader副本复制完 消息就被认为是成功提交(all=1)

Kafka的设计思路：可靠性与性能的tradeoff

复制机制（消息存储方式）不变 但是使用HW来保证消费端消费到的消息都是已经可靠地持久化了的



## 生产者

**分区器**：根据key为消费者分配分区



**生产者整体架构**

![image-20230602075607564](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202306020756616.png)

两个线程：

- 主线程：将消息添加到消息累加器（批处理）

- Sender线程：从消息累加器中获取消息 发送到broker

  客户端会缓存已经发了但是没有收到响应的请求



元数据的更新：通过向负载最小的broker（未确认的消息最少的node）发元数据请求消息



linger.ms：ProducerBatch被填满或者超过了linger.ms的时间 才会被发送出去（这里应该是指从累加器移动到InFlightRequests）



## 消费者

**消费者与消费组**

![image-20230703082618939](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202307030826038.png)

一个分区中的消息只能被一个消费组中的一个消费者消费



消息投递模式：

- 点对点

  一个消息只能被一个消费者消费（所有消费者都属于一个消费组的情况）

- 发布订阅

  一个消息可以被所有订阅的消费者消费（消费者属于不同的消费组）



**位移提交**：

向broker提交消费者消费到的位置，这样在消费者重启的时候，才能知道上次消费到的位置

提交的偏移是分区中下一条要拉取的消息的位置



位移提交的异常情况：

- 重复消费

  消费到了 但是位移及时提交

- 消息丢失

  位移提前提交了 但是没消费

本质上是要保证消息消费-位移提交 这两个动作的原子性



位移提交方式：

- 自动

  每隔5s就会将每个分区中已经拉取到的最大消息位移提交（不管有没有被消费）

- 手动

  - 同步

    也是会根据poll()方法拉取的最新位移提交

    也可以指定位移

  - 异步

    不会阻塞消费线程



**指定位移消费**

查找不到消费位移的情况：

- 消费者组新建立

- 消费组内的消费者订阅了一个新主题

- 这个主题关于这个消费组的位移信息过期被删除

  某个主题下 不同消费组的消费速度可以是不一致的



此时会根据默认配置来：

- 分区末尾（指向下一条要写入消息的位置）
- 分区开头



指定位移步骤：

- seek：已知特定的消费位置

1. poll中消费者分配到分区
2. seek中 指定分区和分区对应的位移

- offsetsForTimes：不知道消费位置 但是知道时间

  返回时间戳>=指定时间的第一条消息对应的位置和时间戳

  

一般做法：

1. 消费完一个分区之后

   将这个分区对应的消费位移存储起来

   partition -> offset

2. 下次拉取到分区的消息的时候 直接从存储中获取 使用seek



**再均衡**

将分区的所有权从消费组内的一个消费者移交到另一个消费者身上

期间整个消费组都不可用



**多线程实现**

KafkaConsumer不是线程安全的

多线程方式：

- 线程封闭

  一个线程内一个KafkaConsumer

  ![image-20230720195057055](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202307201950172.png)

- 多个消费线程同时消费一个分区（不推荐）

- 一个线程拉取 多个线程消费

  tips：防止拉取过快 线程池无法消费 可以使用CallerRunsPolicy拒绝策略

  可以用滑动窗口的思想控制同时处理的批数与提交位移

  处理完的批次就提交位移，startoffset悬停的时候 重试消费->重试队列->死信队列
  
  ![image-20230724193815163](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202307241938231.png)
  
  
  



## 主题与分区

**主题 分区 副本 日志的关系**

![image-20230725194056596](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202307251940647.png)



**分区管理**

- 优先副本选举

  场景：broker所在节点挂掉了之后 某个节点上的broker副本过多 导致负载不均衡的现象

  分区中指定优先成为leader副本的brokerId

- 分区重分配

  场景：节点挂了 节点上的leader分区副本需要被重新迁移到其他节点上
  
  基本原理：增加新的副本 进行数据同步 删除旧的副本

- 复制限流

  限制副本间的复制流量



## 日志存储

**日志存储布局**

![image-20230819093747286](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308190937401.png)

**日志格式的演变**

- v0

  偏移 消息大小

  消息内容

  消息集：一个或多个消息 传输 存储 压缩的基本单位

- v1

  内容部分多了一个timestamp字段

  值为生产者创建时间

- v2

  压缩RecordBatch中的Records

  减少字节数的方法：

  - 使用varints 不同大小的数字用不同大小的字节表示
  - 消息(record)中用与batch初始时间戳的差值 和初始位移的差值 进一步减少使用的字节数



> 编码技巧：
>
> 变长整型：
>
> 每个字节最高位用来表示元信息 1为开始 0为结束
>
> 数字1
>
> 0000 0001
>
> zigzag编码：将有符号整数映射为无符号整数 使得绝对值比较小的负数 也能有较小的varint编码值
>
> ![image-20230819105258267](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308191052321.png)



**日志索引**

每个日志分段文件都对应两个索引文件（都是稀疏索引 key递增 便于二分），日志分段文件被切分时  对应的索引文件也需要切分

- 时间戳索引

  时间戳 -> 偏移量（相对）

  timestamp(8B) -> relativeOffset(4B)

  ![image-20230830064413695](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308300644752.png)

- 偏移量索引

  偏移量(4B) -> 物理地址(4B)（日志分段文件中的）

  ![image-20230830064747502](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308300647537.png)

内存中用跳表维护了

baseOffset -> 日志分段对象的映射



**日志清理**

- 日志删除

  直接删除不符合条件的日志分段

  条件维度：

  - 时间
  - 日志大小
  - 日志起始偏移量

- 日志压缩

  相同key 只保留最新一个版本的value

  cleaner checkpoint：划分了已经compact过了的日志分段 和 没有compact过了的日志分段

  ![image-20230830065759235](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308300657281.png)

  

**磁盘存储**（重点）

> 预读（提前将一个磁盘块读入内存） 
>
> 后写（将很多小的逻辑写操作 合并为一个大的物理写操作）

顺序写盘的速度 还快于 随机写内存的速度，所以kafka写入消息是文件追加的方式 属于顺序写盘操作

![image-20230830070247775](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308300702820.png)



- 页缓存（操作系统）

  不用进程内的内存缓存 直接write()

  消息直接写入页缓存 由操作系统刷盘 可靠性由多副本机制保障 而不由同步刷盘机制保障

- 磁盘IO场景：

  - 调用标准库IO：应用程序buffer -> 库buffer -> 文件系统页缓存 -> 磁盘
  - 调用文件IO：应用程序buffer -> 文件系统页缓存 -> 磁盘
  - 打开文件时标明O_DIRECT：绕过页缓存 直接读写磁盘

- 磁盘IO流程

  - 写操作：

    fwrite 吧数据写入C库标准IObuffer后返回

    IObuffer中将多次小数据量且相邻的写操作缓存起来 合并成一次write写入页缓存

    等待内核线程检查脏页刷盘

  - 读操作：

    fread 到C库标准IObuffer读数据

    没有则查页缓存

    没有则发起IO请求 把结果放到页缓存和IObuffer中 并返回

    ![image-20230830083431781](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308300834830.png)

- 零拷贝

  将数据直接从磁盘文件复制到网卡设备中

  不需要再绕一层应用程序 底层是依赖sendfile()

  ```c
  // 文件内容被复制了4次
  read(file, buf, len);
  write(socket, buf, len);
  ```

  ![image-20230830083932239](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308300839286.png)

  零拷贝：

  Socket buffer获得了指向read buffer的文件描述符

  由DMA将文件内容复制到内核中的read buffer 

  然后也是由DMA 将文件内容传递到网卡设备

  ![image-20230830084216076](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202308300842123.png)

  



## 深入服务端

**协议设计**

- 生产：

  - 请求：

    事务id

    acks

    主题-分区的数据

  - 响应

    主题-分区的 偏移量

- 消费：

  - 请求

    主题-分区-偏移量

  - 响应

    主题-分区



**时间轮**

不同的轮负责不同的时间跨度

![image-20230906201919115](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202309062019272.png)

主要是为解决定时/延时任务数量过多的问题，推进时间用的还是DelayQueue，只不过数量级从任务数 降级到了时间轮的刻度数之和



**控制器**

controller：一个特殊的broker

- 分区的leader副本出现故障时 由controller选举出新的leader副本
- 分区的ISR集合发生变化时  同步给素有的broker

选举控制器：

1. 每个broker启动时 尝试读取zk中的/controller节点 如果不为-1 则表明已有控制器

   ```json
   /controller
   {
     "brokerid":0
   }
   
   ```

   

2. 为-1或/controller节点不存在 或数据异常 则可以尝试竞选

3. 多个尝试竞选的broker只有一个会成功



controller_epoch 控制器纪元 表明是第几代选出的控制器 每次与控制器交互的请求都会带上

- 请求epoch值小于当前值 则会认为是无效
- 请求epoch值大于当前值 则说明有新的控制器当选了



==控制器上下文信息更新中避免并发操作的方式==

将修改共享数据的操作 封装成事件放入队列中 由一个单独的线程来取出事件 对共享数据进行处理 不需要进行线程同步



优雅关闭：

1. 获取进程号
2. 通过对进程发送特殊的信号 
3. 进程在信号处理器中 进行资源的关闭（kafka中是消息持久化到磁盘 对broker上的leader副本进行迁移）



分区leader副本的选举：由控制器 从AR集合中的副本的顺序 找到第一个存活的副本（并且这个副本在ISR集合中）



**服务端参数**

- broker.id

  静态配置：配置文件

  动态生成：依赖zk中的/brokers/seqid中返回的verion值

- bootstrap.servers

  本质上是用来发现kafka集群元数据信息的服务地址 





## 客户端

**分区分配策略**

如何将某个主题的分区 分配给订阅了这个主题的消费组的消费组的 目的是保证同一组的消费者之间负载均衡

- RangeAssignor

  































































