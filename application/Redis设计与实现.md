# Redis设计与实现

[TOC]

## 数据结构与对象

### 简单动态字符串

SDS: *simple dynamic string* 

使用场景：可以看成一个动态的字节数组

- Redis默认的字符串表示
- 缓冲区：AOF缓冲区 客户端的输入缓冲区



**SDS定义**

```c
struct sdshdr {
   // 记录buf数组中已使用的字节数量
   int len;
  	// 未使用的字节数量
   int free;
  	// 字节数组
   char buf[];
}
```

![image-20221218172436139](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212181724175.png)



**相对于C字符串 SDS的好处**

- 获取字符串长度时间复杂度

  - C：O(n) 遍历到`\0`为止

  - SDS：O(1)

- 解决缓冲区溢出问题

  - C：会有缓冲区溢出问题 如果被strcat的目标字符串没有足够的空间 那么会溢出覆盖后面的内存空间

  - SDS：添加字符串的内容时 会检查空间大小 如果不满足 则重新分配空间 再执行修改操作

- 减少修改字符串时带来的内存重分配次数

  - C：增长或缩短字符串 都需要进行内存重分配
  - SDS：有未使用空间 可以实现空间预分配和惰性空间释放 

- 二进制安全
  - C：除了字符串末尾外 其他地方不能包含空字符 所以只能保存文本数据 不能保存其他二进制数据
  - SDS：可以保存文本数据和任意二进制数据

- 兼容部分C字符串函数

  SDS也会将保存的数据末尾设置为空字符 是为了重用一部分`<String.h>`的库

  



### 链表

使用场景：

- List数据类型
- 发布与订阅 慢查询 监视器
- 保存多个客户端的状态信息
- 构建客户端输出缓冲区



**链表节点与链表的实现**

链表节点

![image-20221219083418481](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212190834516.png)

链表

![image-20221219083446108](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212190834129.png)





### 字典

使用场景：

- 实现数据库 Redis本身就是一个字典 两个哈希表
- 实现哈希数据类型



**字典的实现**

哈希表

![image-20221219084406417](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212190844443.png)



哈希表节点

![image-20221219084507341](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212190845368.png)



字典：两个哈希表组成

![image-20221219084602795](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212190846820.png)



**rehash**

步骤：

1. 为ht[1]分配空间
   - 扩展：ht[1] size 为 >= ht[0].used * 2 的第一个 2^n (保证load factor <= 0.5)
   - 收缩：ht[1] size 为 >= ht[0].used  的第一个 2^n （保证load factor <= 1）
2. 将ht[0]中所有键值对rehash到ht[1]上
3. 释放ht[0] 将ht[1]设置为ht[0] 在ht[1]创建一个空白哈希表

扩展和收缩的时机：

- 扩展：

  - 服务器没有在执行bgsave或bgrewriteraof命令 且哈希表负载因子>=1
  - 服务器在执行bgsave或bgrewriteaof命令 且哈希表负载因子>=5

- 收缩：

  哈希表负载因子< 0.1

渐进式rehash：避免一次性rehash整个哈希表用时过长 导致服务不可用

每次对字典进行增删查改操作的时候 执行完指定操作后 还会顺带将bucket上的所有键值对rehash到ht[1]

期间的删除 查找 修改在两个哈希表上进行，查找先在ht[0]中找 没找到再到ht[1]中找

新增的键值对都会保存到ht[1]中



### 跳跃表

使用场景：

- 实现有序集合
- 在集群节点中用作内部数据结构



**跳跃表的实现**

![image-20221221081001754](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212210810819.png)

跳跃表节点：

![image-20221221081129295](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212210811324.png)

- 层：

  一个新跳表节点创建的时候 都会随机生成1-32的层高 每层元素都有前进指针

- 前进指针：

  每个节点每层都有的指向表尾方向元素的指针

- 跨度

  记录两个节点之间的距离 用来计算ranking 寻找节点中的跨度累加就是节点的排位

- 后退指针：

  用于表尾向表头方向访问

- 分值和成员

  score 是个浮点数 节点都按score从小到大排序 不同节点可以相同

  obj 是一个指向SDS的指针 必须唯一





### 整数集合

使用场景：当一个集合只包含整数值元素 且元素数量不多时

![image-20221221085156776](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212210851814.png)

数值从小到大排列，放置的元素能用16bit保存就都用16bit 否则用32bit 64bit 

升级是每个格子都一起升级 这样可以在元素范围不大时 节省内存空间 同时又有一定的灵活性 但是不能降级



### 压缩列表

使用场景：列表键中只包含少量列表项 并且元素为小整数值或长度较短的字符串时

目的：节省内存 充分利用CPU缓存

![image-20221225161036154](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212251610251.png)

![image-20221225161220504](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212251612537.png)









### 压缩列表

> 现在是quicklist

使用场景：列表键中的元素数目少 且元素为小整数值或短字符串

列表构成：

- 占用字节数
- 尾结点偏移量（用于从后往前遍历）
- 节点数量
- 节点
- 末端标识

节点构成：

- 前一个节点的长度（用于从后往前遍历）（1B或5B）
- 内从中的数据类型和长度
- 内容：字节数组或整数



**连锁更新**

出现原因：当前面的节点长度从 <254B 增长到>=254B时 当前节点中previous_entry_length的长度会从1B变化到5B 如果一连串连续的节点都是250-253B之间 程序就会不断执行空间重分配操作（每个节点都来一次）

影响不大，因为出现概率不高



### 对象

对象类型（值的类型）：string list hash set sorted set  

每一种对象类型都用到了至少一种前面的数据结构



**对象类型和编码**

键和值都是一个redisObject对象

对象构成：

- type：值的类型
- encoding：底层数据结构 可以根据数据特征选择最合适的数据结构
- ptr：指向底层数据结构的指针



**字符串对象**

encoding:

- int：value为可以用long表示的整数值 则value直接保存在ptr属性位置
- raw：value为字符串 且长度>32B 则ptr指向一个SDS
- embstr：value为字符串 且字符串长度<=32B ptr 指向的SDS是在内存空间上是紧挨着redisObject的 一是申请和释放内存空间都只需要一次 二是可以更好利用CPU缓存

int和embstr在一定条件下会转化为raw编码



**列表对象**

encoding:

- ziplist：节点元素都小于64B且元素数量小于512  
- linkedlist



**哈希对象**

encoding：

- ziplist：key和value紧挨在一起 先key后value 键和值的长度小于64B  且元素数量小于512个
- hashtable：里面的field和value都是字符串对象



**集合对象**

encoding：

- intset：元素都为整数 且数量小于512
- hashtable：field为字符串对象 value为NULL



**有序集合对象**

encoding：

- ziplist(现在是listpack)

  每个集合元素用两个压缩列表节点表示 第一个为member 第二个为score

  列表内按score从小到大排序

  元素数量小于128且元素长度小于64B

- skiplist: 

  zset：两个数据结构中的member和score的对象都会通过指针共享

  - 跳表：

    按score从小到大排序 用于支持范围型操作

  - 哈希表

    用于支持O(1)复杂度内 查询给定member的score

![image-20221227084628884](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202212270846917.png)



**内存回收**

引用计数实现 redisObject中设置一个引用计数变量refcount，refcount = 0时 对象所占内存会被释放



**对象共享**

多个键共享一个值对象步骤：

- 键的值指针指向一个现有的值对象
- 值对象的引用计数+1

现在(Redis2.08)只共享了0-9999的数值对象，不共享字符串对象或者集合对象的原因是因为检查对象是否相同的时间复杂度比较高



**对象的空转时长**

redisObject中的lru字段记录了对象最后一次被访问的时间

```lua
# 空转时长 = 当前时间 - lru
object idletime key
```



## 单机数据库的实现

### 数据库

**服务器中的数据库**

```c
struct redisServer {
    // 数据库数组 初始情况下有16个 select 0-15切换数据库
    redisDb* db;
    int dbNum;
}
```



**切换数据库**

实际上就是切换redisClient.db指针 指向不同的数据库



**数据库键空间**

```c
typedef struct redisDb {
    // 这个字典就是改数据库的键空间 保存着数据库中所有的键值对
    dict* dict;
} redisDb;
```



在键空间进行读写时额外的维护操作：

- 读取key时 会根据key是否存在更新键空间hit / miss次数
- 读取key时 会更新键的LRU时间
- 读取key时 发现key已经过期 则会先删除这个key 
- 修改某个被客户端watch的key时 会将该key标脏 让事务程序注意到key已经被修改
- 每次修改key时 会对脏键计数器+1 这个计数器会触发持久化和复制操作
- 开启数据库通知功能时 修改key后 将发送相应的数据库通知



过期时间保存：

也是放在一个字典`dict *expires`里面 key为指向键空间中某个对象的键指针 值为过期时间时间戳（ms）

判断一个键是否过期：

- key是否在过期字典中
- key在过期字典中的时间戳是否小于当前时间戳



**过期键删除策略**

需要解决的问题：什么时候将过期的键删除

可选的策略：

- 定时删除：

  设置键的过期键的同时 创建一个延时任务 当键过期时立即删除

  利于内存 不利于CPU

- 惰性删除：

  将过期键的检查和删除操作摊销到每次对键的操作的时候

  利于CPU 不利于内存 过期键不能及时得到删除相当于另一种形式的内存泄漏

- 定期删除：

  创建一个定时任务 每隔一定时间从过期字典中随机抽出一批键进行过期时间的检查 任务每次执行的时长和频率都是可以配置的

Redis实际采用的：惰性 + 定期



**AOF RDB 复制功能对过期键的处理**

- RDB：

  生成时 不会将过期键存入RDB文件中

  载入时 主从模式下 主不会加载过期键 从会加载过期键

- AOF

  删除过期键时 会往AOF文件append一条DEL命令

  重写AOF文件时 不会存入过期的键

- 复制（主从模式下）

  过期键的删除命令由主服务器发出 用于保证主从服务器数据的一致性（要不然某个键在从没有了 在主中还有）

  从服务器的过期键即使被读到也不会删除（现在的版本改为返回null值）



### RDB持久化

需要解决的问题：当Redis进程退出时 内存中保存的数据库状态就会消失 所以需要将数据持久化到磁盘中



**RDB文件创建与载入**

创建：

- `SAVE`

  阻塞创建 期间服务器不可用

- `BGSAVE`

  fork出一个子进程 由子进程进行创建 

  期间服务器可用 但是不能执行新的BGSAVE命令 BGREWRITEAOF命令也会被延迟执行

载入：

当有AOF文件时 优先载入AOF文件（因为数据更为及时） 



**自动间隔性保存**

可用设置多少秒内 数据库进行了多少次修改就触发一次BGSAVE（数据库中维护了两个变量记录了自上次生成RDB命令以来的修改次数和时间）



**RDB文件结构**

- REDIS字符
- db_version：RDB文件版本号
- databases：零个或多个数据库的键值对
- EOF：正文内容的结束
- checksum：前面4个部分的校验和



### AOF持久化

与RDB的区别：

- RDB：保存数据库中的键值对
- AOF：文本格式保存Redis服务器执行的写命令



**AOF持久化的实现**

- 命令追加

  服务器在执行完写命令后 会将写命令追加到内存中的AOF缓冲区(就是一个SDS)的末尾

- 文件写入和同步

  ![image-20230103090339475](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301030903569.png)

  一个事件循环会考虑一次是否将AOF缓冲区的内容flush到AOF文件中

  always：每次事件循环都flush(fsync fdatasync) 最慢 但是最多丢失一个事件循环内的命令数据

  everysec：超过1s flush 性能与数据安全性的权衡 最多丢失1s内的命令数据

  no：每次事件循环只调用write 没有flush 只是放到内核缓冲区 何时flush由操作系统决定 将丢失上次操作系统flush以来的所有写命令数据
  
- 载入与数据还原

  步骤：

  1. 在服务器本地创建一个不带网络连接的伪客户端
  2. 从AOF中分析并读取一条写命令
  3. 使用伪客户端执行命令
  4. 循环直到AOF文件中的写命令被处理完



AOF文件中的问题：一个键值对会对应多条写命令 写命令冗余 

**AOF重写**

根据数据库中的键值对 重新生成一个新的AOF文件来替代旧的AOF文件 避免冗余

实现：从数据库中读取键值对 然后只用一条写命令记录键值对 代替之前记录键值对的多条命令 都是在子进程中完成的

使用子进程原因：

- 避免服务阻塞 影响正常请求的处理
- fork copy-on-write 可以在避免用锁的情况下 保证数据安全性 

使用子进程带来的问题：子进程生成AOF文件期间接收到的写命令如何处理

解决：在子进程进行AOF重写期间 主进程将写命令也写到AOF重写缓冲中 等待接收到子进程完成信号后 在信号处理函数中会将AOF重写缓冲区写入到新的AOF文件中



### 事件

事件类型：

- 文件事件：对套接字操作的抽象 分为读事件和写事件
- 时间事件：对定时操作的抽象



**文件事件**

文件事件处理器组成：

- 多个套接字
- IO多路复用程序：底层为各个操作系统的api 如select/epoll
- 文件事件分排器（一个队列）
- 事件处理器

![image-20230109083422372](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301090834412.png)



**时间事件**

分类：

- 定时事件：在指定时间之后执行一次
- 周期性事件：每个指定时间就执行一次

组成：

- id
- when：时间事件应该被处理的时间
- timeProc：时间事件处理器 当时间事件应该被处理时 服务器就会调用相应的处理器来处理事件

实现：

将所有时间事件都放在一个无序链表中 每当时间事件执行器运行时 会遍历链表找到已经到达的时间事件 调用对应的事件处理器 如果是周期性事件 则会重置到达时间为将来的一个时间点



**事件的调度与执行**



![image-20230109090010365](https://daxiao-img.oss-cn-beijing.aliyuncs.com/img/202301090900396.png)

每个事件循环中需要做的事 可以学习的点：先处理文件事件 再处理时间事件 用时间事件的准备到达时间来决定等待文件事件的阻塞时间长度（可以避免频繁轮询时间事件 相当于sleep到事件执行时间 ）



### 客户端

**输入缓冲区**

保存客户端发送的命令请求 实际上就是一个SDS



**输出缓冲区**

保存服务端执行命令的回复

- 固定缓冲区：char数组 用于保存长度较小的回复
- 可变大小缓冲区：字符串链表



**客户端的创建与关闭**

- 创建：

  服务器调用连接事件处理器

  为客户端创建客户端状态redisClient

  并将这个状态添加到客户端链表末尾

- 关闭原因

  - 客户端进程销毁
  - 客户端发送不符合协议的请求
  - 客户端被CLIENT KILL
  - 空转时间超过timeout
  - 输入缓冲区溢出
  - 输出缓冲区溢出
    - 硬性限制：超过立即关闭客户端
    - 软性限制：一段时间内持续超过 才关闭客户端



**伪客户端**：没有网络连接的

- Lua脚本 整个服务器生命周期一直存在
- AOF文件 只会在执行AOF文件时存在





### 服务器

**命令请求的执行过程**

1. 发送命令请求

   set key value

   客户端将命令转换为协议格式（实际上还是文本）

2. 读取命令请求

   连接套接字可读 产生事件

   读取命令请求 并将其放在客户端的输入缓冲区中

   对缓冲区中的命令请求进行分析 解析出参数列表 argv[]

   调用命令执行器

   > 命令执行器：
   >
   > 1. 在命令表中查找命令argv[0] set get这些 找到后将redisCommand指针放到cmd属性中
   > 2.  执行预备操作 参数校验 服务器状态校验等
   > 3. 调用命令的实现函数
   > 4. 执行后续工作 统计 AOF 复制

3. 将命令回复发送给客户端

   将回复写到客户端的输出缓冲区中 当客户端的套接字变为可写时 调用命令回复处理器进行数据发送



**serverCron**：0.1s执行一次的定时任务

- 检查是否收到SIGTERM信号 如果收到 在进行RDB持久化操作后 再退出
- 客户端资源管理：释放超时连接与输入缓冲区
- 数据库资源管理：删除过期键 收缩字典等
- 将AOF缓冲区的内容写入到AOF文件



**初始化服务器**

1. 初始化服务器状态结构
2. 载入配置
3. 初始化数据结构
   - 客户端链表
   - 数据库数组
4. 载入RDB或者AOF文件
5. 执行事件循环



## 多级数据库的实现

### 复制

**旧版复制功能的实现**

- 同步：从服务器的数据库状态更新到与主服务器一致

  从 -> 主：SYNC命令

  SYNC命令的执行内容：

  1. 从 -> 主：SYNC

  2. 主：执行BGSAVE 同时生成一个buffer记录此刻开始的所有写命令

  3. 主：BGSAVE执行完成，将生成的RDB文件发送给从服务器

     从：接收并载入RDB

  4. 主：将buffer中的所有写命令发送给从服务器

     从：执行这些写命令

- 命令传播：将主服务器中的修改命令传播到从服务器 会存在一定的时间延迟



**旧版复制功能的缺陷**

复制类型：

- 初次复制：重新生成RDB 并加载没问题
- 断线后复制：有问题 因为其实只需要 



**新版复制功能的实现**

PSYNC runid offset

- 初次复制：完整重同步 同SYNC
- 断线后复制：部分重同步 主服务器只将主从断开期间的执行的写命令发送给从服务器



**部分重同步的实现**

组成：

- 复制偏移量 主从都有

  主：每向从服务器传播N个字节的数据 复制偏移量就加上N

  从：每收到主服务器的N个字节的数据 复制偏移量加上N

  主从的复制偏移量一致 说明主从数据库状态一致

- 主服务器的复制积压缓冲区（一个固定长度的FIFO 默认大小为1MB 可以根据主服务器的写命令产生速度和断线重连的平均时间调整）

  保存最近传播的写命令

  如果PSYNC 传过来的从服务器的复制偏移量小于主服务器的复制偏移量 且还能从复制积压缓冲区中找到话 就将这部分的写命令字节传播过去

- 服务器的运行ID

  断线重连时 如果主从切换了 那就只能完整重同步 所以需要从服务器保存之前同步的主服务器的runID



**复制的实现**

SLAVEOF命令

1. 设置主服务器的地址和端口

2. 从服务器建立套接字连接 并为这个关联一个专门用于处理复制工作的文件事件处理器

   此时从服务器成为了主服务器的一个客户端

3. 从向主发送PING命令 检查套接字读写是否正常 检查主服务器是否可以正常处理命令请求

4. 身份验证

5. 从服务器向主服务器发送端口信息

6. PSYNC 执行PSYNC之后 主服务器也会成为从服务器的客户端 即可以向从服务器发送命令

7. 命令传播



**心跳检测**：1s一次

- 检测主从网络连接状态
- 会影响主从集群可用性 min-slaves
- 检测是否有丢失的写命令 通过检查复制偏移量是否一致（相当于一个兜底机制）



### Sentinel

实际上就是一个运行在特殊模式下的Redis服务器

作用：用于监视主服务器，当主服务器下线时 将从服务器升级为主服务器继续提供服务



**启动并初始化Sentinel**

- 初始化服务器
- 执行Sentinel专用代码
- 初始化Sentinel状态
- 初始化监视主服务列表
- 创建和主服务器的网络连接
  - 命令连接：向主服务器发送命令 并接收回复
  - 订阅连接：订阅主服务器的频道



**获取主服务信息**

每10s一次向主服务器发送INFO命令

信息内容：

- 主服务器
- 从服务器：更新slaves字典 key: ip+port value:实例



**获取从服务器信息**

通过主服务器的回复来获取从服务器的地址，然后跟从服务器建立命令连接和订阅连接，通过10s一次的INFO命令获取信息

信息内容：

- run_id
- role:master/slave
- 主服务器的:ip port
- 主从服务器的连接状态
- 从服务器的优先级
- 从服务器的复制偏移量



**向主服务器和从服务器发送信息**

2s一次，通过命令连接向主从的频道发送消息

消息内容：

- sentinel自身信息
- master信息



**接收来自主从的频道信息**

订阅`_sentinel_:hello`频道 可以接收到其他sentinel发来的消息（主要用于发现未知的sentinel）

如果发送消息的run_id跟自己不同就分析消息

- 更新sentinels字典
- 创建连向其他sentinel的命令连接（可以用于之后的判断客观下线和leader选举）



**检测主观下线状态**

每1s向所有建立了命令连接的实例（主 从 其他Sentinel）发送PING命令，根据回复情况来判断是否在线

回复：

- 有效：PONG LOADING MASTERDOWN
- 无效：其他回复 或者指定时限内没有回复 

指定时限：down-after_milliseconds

一个实例在指定时限内没有回复或者无效回复，则会被该sentinel判断为主观下线



**检测客观下线状态**

当一个sentinel判断主服务器主观下线后 会通过命令连接向其他sentinel询问他们是否也认为主服务器下线（主观或客观），当接收到足够数量（quorum）的下线判断后，sentinel判断主为客观下线，然后执行故障转移



**选举leader sentinel 由leader执行故障转移**

选举过程：

1. 当某个sentinel判定主为客观下线时 要求其他sentinel将自己设置为局部leader(局部的意思是 本次epoch的 下次不一定是)
2. 每个sentinel会对第一个发送过来的要求 做出肯定回答 同意设置其为leader
3. 当sentinel被半数以上的sentinel设置为leader时 leader选举完成 如果数量不够 则过一段时间再次进行选举 直到选出为止



**故障转移**

由leader对已下线的主服务器执行故障转移操作

1. 从从服务器中挑选出一个成为主服务器

   `slaveof no one`

   主服务器挑选规则：

   - 排除下线或者断线状态的
   - 排除最近5s没有回复INFO命令的
   - 排除与之前的主服务器断开连接时间超过down-after-ms * 10的从服务器（保证从服务器中的数据都是比较新的）
   - 排序规则：优先级 复制偏移量 run_id

2. 让其余从服务器改为复制新的主服务器

   `slaveof ip port`

3. 让已下线的主服务器改为从服务器 等待其重新上线

   `slaveof ip port`























